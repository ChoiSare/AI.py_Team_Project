import os  
import re
import requests
import urllib.request 
from bs4 import BeautifulSoup as soup

def get_google_image_urls(keyword):
    ptn = re.compile(r'^https?://')
    base_url = 'https://www.google.co.kr/search'
    params = {'q': keyword, 'tbm': 'isch'}
    res = requests.get(base_url, params=params)
    doc = soup(res.text, 'html.parser')
    return [e.get('src') for e in doc.find_all('img') if ptn.match(e.get('src'))]

def download_image(url, filename):
    try:
        res = requests.get(url)
        if res.status_code != 200:
            return ''
        type = res.headers['Content-Type']

        ext = ''
        if type == 'image/jpeg':
            ext = '.jpg'
        elif type == 'image/png':
            ext = '.png'
        elif type == 'image/gif':
            ext = '.gif'
        else:
            return ''

        filename = '{}{}'.format(filename, ext)
        with open('filename', 'wb') as f:
            f.write(res.content)
        return filename
    except:
        return ''

def change_name(new_name):  # img 폴더 이름 변경하는 함수 추가
    directory = os.listdir('C:\\Users\\User\PycharmProjects\Link_Crawler')
    os.rename('img', new_name)


if __name__ == '__main__':
    os.mkdir('C:\\Users\\User\PycharmProjects\Link_Crawler\img')  # img 폴더 생성하는 함수 추가
    search = input('검색어를 입력하세요(쉼표로 구분, 여러 개 가능)')  # 검색어 입력 받는 기능 추가
    keywords = search.split(',')  # 입력 받은 검색어 리스트 형태로 변환

    keywords = ['표정']
    urls = []
    for keyword in keywords:
        urls = [*urls, *get_google_image_urls(keyword)]
    for i, url in enumerate(urls, start=1):
        filename = download_image(url, '{:03d}'.format(i))
        if filename:
            print('download {} -> {}'.format(url, filename))
            urllib.request.urlretrieve(url, './img/' + filename)  # img 폴더에 파일 저장하는 함수 추가
            
change_name(search)  # 이미지 저장시킨 폴더의 이름 변경
